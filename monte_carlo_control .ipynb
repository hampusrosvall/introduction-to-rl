{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grid_world import negative_grid, standard_grid\n",
    "from iterative_policy_evaluation import print_values, print_policy \n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an episode of the game \n",
    "\n",
    "GAMMA = 0.9 \n",
    "ALL_POSSIBLE_ACTIONS = ('U', 'D', 'L', 'R')\n",
    "grid = negative_grid(step_cost = -0.9)\n",
    "\n",
    "def play_game(policy, grid): \n",
    "    '''\n",
    "    plays one episode of the grid world game \n",
    "    returns: a state, action, return triplet of the game \n",
    "    '''\n",
    "    \n",
    "    # random initialize starting state and action \n",
    "    starting_states = list(grid.actions.keys()) \n",
    "    starting_index = np.random.choice(len(starting_states))\n",
    "    state = starting_states[starting_index]\n",
    "    action = np.random.choice(ALL_POSSIBLE_ACTIONS)\n",
    "    \n",
    "    # set grid to current state \n",
    "    grid.set_state(state)\n",
    "    seen_states = set()\n",
    "    seen_states.add(grid.current_state())\n",
    "    \n",
    "    # append starting state, action and return 0 since starting state doesn't generate any reward \n",
    "    # as r(t) results from taking action a(t-1) from s(t-1) and landing in s(t)\n",
    "    states_actions_rewards = [(state, action, 0)]\n",
    "    \n",
    "    # i.e. we start in state: state and perform action and will then get some reward \n",
    "    num_steps = 0 \n",
    "    while True: \n",
    "        # perform the action and cache the resulting reward given action: action \n",
    "        reward = grid.move(action) \n",
    "        \n",
    "        # the state we end up in due to action: action \n",
    "        state = grid.current_state() \n",
    "        \n",
    "        # increment num_steps \n",
    "        num_steps += 1 \n",
    "        \n",
    "        # check of we ended up in the same state\n",
    "        if state in seen_states: \n",
    "            # if we bumped into a wall the reward is set to -10 and we end the episode \n",
    "            # append the action None as we shouldn't perform an action in a terminal state \n",
    "            reward = -10 / num_steps \n",
    "            states_actions_rewards.append((state, None, reward))\n",
    "            break \n",
    "            \n",
    "        # the next conditional checks if the game is over \n",
    "        elif grid.game_over(): \n",
    "            # append the state, action, reward triple and break out of the while-statement  \n",
    "            states_actions_rewards.append((state, None, reward))\n",
    "            break \n",
    "            \n",
    "        # else we continue playing, choose an action given the state\n",
    "        # append the state, action, reward triplet i.e. \n",
    "        # being in state s(t), performing action a(t) and getting the reward r(t + 1)\n",
    "        else:\n",
    "            action = policy[state]\n",
    "            states_actions_rewards.append((state, action, reward))\n",
    "            \n",
    "        seen_states.add(state)\n",
    "        \n",
    "    # when the while-statement is finished we need to calculate the return for each visited state \n",
    "    # we need to do this so that the terminal state has zero return\n",
    "    \n",
    "    first = True \n",
    "    states_actions_returns = []\n",
    "    G = 0 \n",
    "    for state, action, reward in reversed(states_actions_rewards): \n",
    "        if first: \n",
    "            # we encounter the terminal state - set first to false \n",
    "            first = False\n",
    "        else: \n",
    "            # we should add the state, action, return triple \n",
    "            states_actions_returns.append((state, action, G))\n",
    "            \n",
    "        # G is updated as r(t + 1) + GAMMA * G(t + 1)\n",
    "        G = reward + GAMMA * G\n",
    "    \n",
    "    states_actions_returns.reverse()\n",
    "    return states_actions_returns\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "-0.10|-0.10|-0.10| 1.00|\n",
      "---------------------------\n",
      "-0.10| 0.00|-0.10|-1.00|\n",
      "---------------------------\n",
      "-0.10|-0.10|-0.10|-0.10|\n"
     ]
    }
   ],
   "source": [
    "# print rewards \n",
    "\n",
    "print_values(grid.rewards, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "  R  |  R  |  R  |     |\n",
      "---------------------------\n",
      "  U  |     |  U  |     |\n",
      "---------------------------\n",
      "  U  |  R  |  U  |  L  |\n"
     ]
    }
   ],
   "source": [
    "# initialize pi at random \n",
    "import operator \n",
    "policy = {}\n",
    "for state in grid.actions: \n",
    "    policy[state] = np.random.choice(ALL_POSSIBLE_ACTIONS)\n",
    "    \n",
    "# initialize Q and returns \n",
    "returns = {}\n",
    "Q = {}\n",
    "\n",
    "for state in grid.all_states(): \n",
    "    if state in grid.actions: \n",
    "        Q[state] = {}\n",
    "        for action in ALL_POSSIBLE_ACTIONS: \n",
    "            Q[state][action] = 0\n",
    "            returns[(state, action)] = []\n",
    "            \n",
    "# repeat \n",
    "deltas = list()\n",
    "for _ in range(10000):\n",
    "    states_actions_returns = play_game(policy, grid)\n",
    "    \n",
    "    # to cope with first-visit monte carlo approach \n",
    "    seen_pairs = set()\n",
    "    delta = 0\n",
    "    for state, action, G in states_actions_returns: \n",
    "        if (state, action) not in seen_pairs: \n",
    "            returns[(state, action)].append(G)\n",
    "            old_action_value = Q[state][action]\n",
    "            Q[state][action] = np.mean(returns[(state, action)])\n",
    "            change = max(delta, np.abs(Q[state][action] - old_action_value))\n",
    "            seen_pairs.add((state, action))\n",
    "    deltas.append(change)\n",
    "    \n",
    "    for state in grid.actions: \n",
    "        policy[state] = max(Q[state].items(), key=operator.itemgetter(1))[0]\n",
    "        \n",
    "print_policy(policy, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11493f470>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "-0.34|-0.11| 1.00| 0.00|\n",
      "---------------------------\n",
      "-0.63| 0.00|-0.25| 0.00|\n",
      "---------------------------\n",
      "-1.20|-1.08|-0.57|-0.98|\n"
     ]
    }
   ],
   "source": [
    "V = {}\n",
    "for k, v in Q.items():\n",
    "    max_key = max(v.items(), key=operator.itemgetter(1))[0]\n",
    "    V[k] = v[max_key]\n",
    "    \n",
    "print_values(V, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
